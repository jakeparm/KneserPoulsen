{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rv_continuous\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for implementing a RV\n",
    "# https://docs.scipy.org/doc/scipy/dev/contributor/adding_new.html#adding-a-new-statistics-distribution\n",
    "# Similarly implemented RV: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gennorm.html#scipy.stats.gennorm\n",
    "\n",
    "'''\n",
    "Implementation with varying p\n",
    "\n",
    "class special_exp(rv_continuous):\n",
    "    def __init__(self, p, *args, **kwargs):\n",
    "        self.p = p\n",
    "        self.constant = 1 / (2*gamma(1+1/self.p))\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def _pdf(self, x): #https://docs.scipy.org/doc/scipy/tutorial/stats/sampling.html\n",
    "        return self.constant * np.exp(-np.abs(x)**self.p)\n",
    "'''\n",
    "\n",
    "\n",
    "class special_exp(rv_continuous): \n",
    "    def _pdf(self, x): #https://docs.scipy.org/doc/scipy/tutorial/stats/sampling.html\n",
    "        return 1/2 * np.exp(-np.abs(x))\n",
    "    \n",
    "    def _cdf(self, x):\n",
    "        if x >= 0:\n",
    "            return 1/2 + 1/2 * (1-np.exp(-x))\n",
    "        else:\n",
    "            return 1/2 * np.exp(x)\n",
    "\n",
    "    def _ppf(self, x):\n",
    "        if x <= 1 and x >= 1/2:\n",
    "            return -np.log(1-2*(x-1/2))\n",
    "        else:\n",
    "            return np.log(2*x)\n",
    "\n",
    "def inv_cdf(x):\n",
    "    if x >= 1/2:\n",
    "        return -np.log(1-2*(x-1/2))\n",
    "    else:\n",
    "        return np.log(2*x)\n",
    "\n",
    "# Generate g vector\n",
    "def gen_g(n):\n",
    "    g = []\n",
    "    u = np.random.uniform(0,1,n)\n",
    "    for u_i in u:\n",
    "        g_i = inv_cdf(u_i)\n",
    "        g.append(g_i)\n",
    "    return g\n",
    "\n",
    "# Generate Z\n",
    "def gen_Z():\n",
    "    return np.random.exponential(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random point in the diamond\n",
    "def gen_point_in_diamond(n, alpha):\n",
    "    g = np.array(gen_g(n))\n",
    "    z = gen_Z()[0]\n",
    "    x = []\n",
    "    for g_i in g:\n",
    "        x_i = g_i / (np.sum(abs(g)) + z)\n",
    "        x.append(x_i)\n",
    "\n",
    "    # Normalize volume\n",
    "    x = alpha * np.array(x) * (gamma(1+n))**(1/n)/2\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random point in the cube\n",
    "def gen_point_in_cube(dimension, bounds=[-1/2, 1/2]):\n",
    "    x = []\n",
    "    for i in range(dimension):\n",
    "        x_i = np.random.uniform(bounds[0], bounds[1])\n",
    "        x.append(x_i)\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances(points):\n",
    "    m = len(points)\n",
    "    #n = len(points[0])\n",
    "    pairwise_distances = np.zeros(shape=(m, m))\n",
    "    i = 0\n",
    "    for point1 in points:\n",
    "        j = 0\n",
    "        for point2 in points:\n",
    "            if i < j:\n",
    "                pairwise_distances[i][j] = np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "            j += 1\n",
    "        i += 1\n",
    "        \n",
    "    return pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_contraction(pairwise_distances1, pairwise_distances2):\n",
    "    upper_triangular = np.triu(np.ones_like(pairwise_distances1, dtype=bool),k=1)\n",
    "    contraction = np.where(upper_triangular, pairwise_distances1 >= pairwise_distances2, True)\n",
    "    if contraction.all():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_volume_of_intersection(centers, n, r, n0=1000000):\n",
    "    all_points = np.concatenate(centers)\n",
    "    all_points = np.abs(all_points)\n",
    "    extreme_point = np.max(all_points)\n",
    "    bounds = np.array([-(extreme_point+r), extreme_point+r])\n",
    "    samples = np.random.uniform(bounds[0], bounds[1], (n0, n))\n",
    "\n",
    "    intersection = sum(all(np.linalg.norm(sample - center) <= r for center in centers) for sample in samples)\n",
    "    volume_box = (bounds[1] - bounds[0])**n\n",
    "    print(f\"intersection: {intersection}\")\n",
    "    volume = (intersection / n0) * volume_box\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_volume_of_intersection_grid(centers, n, r):\n",
    "    n0 = 20**n\n",
    "    num_step = int(np.ceil(n0**(1/n)))\n",
    "\n",
    "    bounds = np.array([-(1+r), 1+r])\n",
    "    steps = np.linspace(bounds[0], bounds[1], num_step)\n",
    "\n",
    "    permutation = list(product(steps, repeat=n))\n",
    "    grid = np.array(permutation)\n",
    "\n",
    "    volume_box = (bounds[1] - bounds[0])**n\n",
    "\n",
    "    intersection = sum(any(np.linalg.norm(sample - center) <= r for center in centers) for sample in grid)\n",
    "    volume = (intersection / n0) * volume_box\n",
    "    \n",
    "    return (volume)**(1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contraction(p, n, r, N, alpha):\n",
    "    # Generate random points\n",
    "    points_in_cube = []\n",
    "    points_in_diamond = []\n",
    "    for i in range(N):\n",
    "        point_i = gen_point_in_cube(n)\n",
    "        points_in_cube.append(point_i)\n",
    "        point_j = gen_point_in_diamond(n, alpha)\n",
    "        points_in_diamond.append(point_j)\n",
    "\n",
    "    # Get pairwise distances and averages\n",
    "    pairwise_distances_cube = get_pairwise_distances(points_in_cube)\n",
    "    pairwise_distances_diamond = get_pairwise_distances(points_in_diamond)\n",
    "    largest_avg_pairwise_distance = np.average(pairwise_distances_cube)\n",
    "    smallest_avg_pairwise_distance = np.average(pairwise_distances_diamond)\n",
    "    \n",
    "    k = 1\n",
    "    # Check for contraction\n",
    "    if check_for_contraction(pairwise_distances_cube, pairwise_distances_diamond):\n",
    "        cube_vol = estimate_volume_of_intersection_grid(points_in_cube, n, r)\n",
    "        diamond_vol = estimate_volume_of_intersection_grid(points_in_diamond, n, r)\n",
    "        return cube_vol, diamond_vol\n",
    "\n",
    "    # Continue to generate new points while updated the largest and smallest pairwise distance averages\n",
    "    while True:\n",
    "        new_points_in_diamond = []\n",
    "        new_points_in_cube = []\n",
    "        for i in range(N):\n",
    "            point_i = gen_point_in_cube(n)\n",
    "            new_points_in_cube.append(point_i)\n",
    "            point_j = gen_point_in_diamond(n, alpha)\n",
    "            new_points_in_diamond.append(point_j)\n",
    "\n",
    "        new_pairwise_distances_cube = get_pairwise_distances(new_points_in_cube)\n",
    "        new_pairwise_distances_diamond = get_pairwise_distances(new_points_in_diamond)\n",
    "\n",
    "        # Update largest\n",
    "        cube_average = np.average(new_pairwise_distances_cube)\n",
    "        if cube_average > largest_avg_pairwise_distance:\n",
    "            points_in_cube = new_points_in_cube\n",
    "            largest_avg_pairwise_distance = cube_average\n",
    "            pairwise_distances_cube = new_pairwise_distances_cube\n",
    "\n",
    "        # Update smallest\n",
    "        diamond_average = np.average(new_pairwise_distances_diamond)\n",
    "        if diamond_average < smallest_avg_pairwise_distance:\n",
    "            points_in_diamond = new_points_in_diamond\n",
    "            smallest_avg_pairwise_distance = diamond_average\n",
    "            pairwise_distances_diamond = new_pairwise_distances_diamond\n",
    "        \n",
    "        \n",
    "        k += 1\n",
    "        \n",
    "        # Check for contraction\n",
    "        if check_for_contraction(pairwise_distances_cube, pairwise_distances_diamond):\n",
    "            cube_vol = estimate_volume_of_intersection_grid(points_in_cube, n, r)\n",
    "            diamond_vol = estimate_volume_of_intersection_grid(points_in_diamond, n, r)\n",
    "            return cube_vol, diamond_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_r(n, r, N, alpha):\n",
    "    df = pd.DataFrame(columns=['n', 'r', 'N', 'alpha', 'cube_vol', 'diamond_vol'])\n",
    "\n",
    "    for radius in r:\n",
    "        cube_vol, diamond_vol = find_contraction(1,n,radius,N,alpha)\n",
    "        temp_df = pd.DataFrame({'n':[n],'r':[radius],'N':[N],'alpha':[alpha],'cube_vol':[cube_vol],'diamond_vol':[diamond_vol]})\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def vary_N(n, r, N, alpha):\n",
    "    df = pd.DataFrame(columns=['n', 'r', 'N', 'alpha', 'cube_vol', 'diamond_vol'])\n",
    "\n",
    "    for N0 in N:\n",
    "        cube_vol, diamond_vol = find_contraction(1,n,r,N0,alpha)\n",
    "        temp_df = pd.DataFrame({'n':[n],'r':[r],'N':[N0],'alpha':[alpha],'cube_vol':[cube_vol],'diamond_vol':[diamond_vol]})\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def vary_alpha(n, r, N, alpha):\n",
    "    df = pd.DataFrame(columns=['n', 'r', 'N', 'alpha', 'cube_vol', 'diamond_vol'])\n",
    "\n",
    "    for alph in alpha:\n",
    "        cube_vol, diamond_vol = find_contraction(1,n,r,N,alpha)\n",
    "        temp_df = pd.DataFrame({'n':[n],'r':[r],'N':[N],'alpha':[alph],'cube_vol':[cube_vol],'diamond_vol':[diamond_vol]})\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_r(df):\n",
    "    n = df['n'][0]\n",
    "    N = df['N'][0]\n",
    "    alpha = df['alpha'][0]\n",
    "\n",
    "    plt.plot(df['r'], df['cube_vol'], label='cube_vol', color='blue', marker='s')\n",
    "    plt.plot(df['r'], df['diamond_vol'], label='diamond_vol', color='red', marker='D')\n",
    "\n",
    "    plt.title(f'Varying r (n={n}, N={N}, alpha={alpha})')\n",
    "    plt.xlabel('r')\n",
    "    plt.ylabel('Vol (Normalized)')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "def graph_N(df):\n",
    "    n = df['n'][0]\n",
    "    r = df['r'][0]\n",
    "    alpha = df['alpha'][0]\n",
    "\n",
    "    plt.plot(df['N'], df['cube_vol'], label='cube_vol', color='blue', marker='s')\n",
    "    plt.plot(df['N'], df['diamond_vol'], label='diamond_vol', color='red', marker='D')\n",
    "\n",
    "    plt.title(f'Varying N (n={n}, r={r}, alpha={alpha})')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('Vol (Normalized)')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def graph_alpha(df):\n",
    "    n = df['n'][0]\n",
    "    r = df['r'][0]\n",
    "    N = df['N'][0]\n",
    "\n",
    "    plt.plot(df['alpha'], df['cube_vol'], label='cube_vol', color='blue', marker='s')\n",
    "    plt.plot(df['alpha'], df['diamond_vol'], label='diamond_vol', color='red', marker='D')\n",
    "\n",
    "    plt.title(f'Varying alpha (n={n}, r={r}, N={N})')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('Vol (Normalized)')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "r = [n**(1/4), n**(1/3), n**(1/2), n]\n",
    "N = 12\n",
    "alpha = .7\n",
    "r_df = vary_r(n, r, N, alpha)\n",
    "r_graph = graph_r(r_df)\n",
    "plt.show(r_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "r = n**(1/2)\n",
    "N = [8,10,12,14]\n",
    "alpha = .7\n",
    "\n",
    "N_df = vary_N(n, r, N, alpha)\n",
    "N_graph = graph_N(N_df)\n",
    "plt.show(N_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "r = n**(1/2)\n",
    "N = 2*n\n",
    "alpha = [.5, .55, .6, .65, .7, .75]\n",
    "alpha_df = vary_alpha(n, r, N, alpha)\n",
    "alpha_graph = graph_alpha(alpha_df)\n",
    "plt.show(alpha_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
